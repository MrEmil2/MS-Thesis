%% Options Definer
maxNumCompThreads(1);           % force single-core processing
fprintf('CPU threads: %d\n',feature('numthreads'))

% Test 1
% Batch Gradient Descent

options1 = trainingOptions("sgdm",...
    "InitialLearnRate",1e-3,...      % BGD requires smaller LR
    "Momentum",0,...
    "MiniBatchSize",64,...        % full batch = 77708
    "Shuffle","never",...
    "MaxEpochs",4000,...
    "LearnRateSchedule","none",...
    "Verbose",true,...
    "Plots","training-progress");

% Test 2
% Min Batch Gradient Descent

options2 = trainingOptions("sgdm",...
    "InitialLearnRate",1e-4,...   % bigger learn rate with bigger batch
    "Momentum",0,...
    "MiniBatchSize",32,...        % typical batch size 32. 64 better, 128 slower
    "Shuffle","every-epoch",...
    "MaxEpochs",400,...
    "LearnRateSchedule","none",...
    "Verbose",true,...
    "Plots","training-progress");

% Test 3
% Stochastic Gradient Descent

options3 = trainingOptions("sgdm",...  % pure SGD is mostly pedagogical
    "InitialLearnRate",1e-3,...    % SGD needs smaller ILR
    "Momentum",0,...            % removed "GradientThreshold",1,...
    "MiniBatchSize",1,...        % for SGD
    "Shuffle","never",...
    "MaxEpochs",400,...
    "LearnRateSchedule","none",...   % don't use piecewise for pure SGD
    "Verbose",true,...
    "Plots","training-progress");

% Test 4
% adaptive learning rate

options4 = trainingOptions("adam",...    % for adaptive learning
    "InitialLearnRate",2e-4,...
    "GradientThreshold",0.5,...     % 0.5 tested best
    "MiniBatchSize",128,...        % trying to smooth
    "Shuffle","every-epoch",...   % also tried shuffle every epoch
    "MaxEpochs",50,...             % reduced because no gain
    "LearnRateSchedule","piecewise",...
    "LearnRateDropFactor",.5,...   % default = 0.1
    "LearnRateDropPeriod",10,...    % default = 10
    "Verbose",true,...
    "Plots","training-progress");

% Test 5
% momentum

options5 = trainingOptions("sgdm",...  % using inputs from test4
    "InitialLearnRate",2e-4,...
    "GradientThreshold",0.5,...
    "Momentum",0,...
    "MiniBatchSize",128,...        
    "Shuffle","every-epoch",...
    "MaxEpochs",50,...
    "LearnRateSchedule","none",...  
    "Verbose",true,...
    "Plots","training-progress");

% Test 6
% L2 regularization

options6 = trainingOptions("adam",...   %should use adam
    "InitialLearnRate",1e-4,...
    "GradientThreshold",0.5,...      % weight decay
    "L2Regularization",0,... 
    "MiniBatchSize",128,...        % using min batch
    "Shuffle","every-epoch",...
    "MaxEpochs",10,...
    "LearnRateSchedule","none",...
    "Verbose",true,...
    "Plots","training-progress");

% Test 7
% Final Optimization

options7 = trainingOptions("adam",...    % for adaptive learning
    "InitialLearnRate",2e-3,...
    "GradientThreshold",0.8,...
    "MiniBatchSize",128,...        % trying to smooth
    "Shuffle","every-epoch",...   % also tried shuffle every epoch
    "MaxEpochs",50,...             % reduced because no gain
    "LearnRateSchedule","piecewise",...
    "LearnRateDropFactor",.2,...   % default = 0.1
    "LearnRateDropPeriod",15,...    % default = 10
    "ValidationData",testDS,...
    "ValidationFrequency",100,...     % iterations per val. train obs/ min batch ~ 600
    "ValidationPatience",50,...       % stoppage, times better than prev
    "Verbose",true,...
    "Plots","training-progress");

options7ML = trainingOptions("adam",...    % MATLAB standard
    "InitialLearnRate",0.001,...
    "GradientThreshold",Inf,...
    "MiniBatchSize",128,...        % trying to smooth
    "Shuffle","every-epoch",...   % also tried shuffle every epoch
    "MaxEpochs",30,...             % reduced because no gain
    "ValidationData",testDS,...
    "ValidationFrequency",100,...     % iterations per val. train obs/ min batch ~ 600
    "ValidationPatience",50,...       % stoppage, times better than prev
    "Verbose",true,...
    "Plots","training-progress");

options7PR = trainingOptions("adam",...    % previous research
    "InitialLearnRate",0.001,...
    "L2Regularization",0.01,...
    "MiniBatchSize",256,...        % trying to smooth
    "Shuffle","every-epoch",...   % also tried shuffle every epoch
    "MaxEpochs",1000,...             % reduced because no gain
    "ValidationData",testDS,...
    "ValidationFrequency",100,...     % iterations per val. train obs/ min batch ~ 600
    "ValidationPatience",50,...       % stoppage, times better than prev
    "Verbose",true,...
    "Plots","training-progress");

options7AN = trainingOptions("sgdm",...    % AlexNet standard
    "InitialLearnRate",0.01,...
    "L2Regularization",0.0005,...
    "Momentum",0.9,...
    "MiniBatchSize",128,...        
    "Shuffle","every-epoch",...   % also tried shuffle every epoch
    "LearnRateSchedule","piecewise",...
    "LearnRateDropFactor",.1,...   % default = 0.1
    "LearnRateDropPeriod",30,...    % default = 10
    "MaxEpochs",90,...             % reduced because no gain
    "ValidationData",testDS,...
    "ValidationFrequency",100,...     % iterations per val. train obs/ min batch ~ 600
    "ValidationPatience",50,...       % stoppage, times better than prev
    "Verbose",true,...
    "Plots","training-progress");